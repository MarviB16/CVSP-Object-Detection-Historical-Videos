{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:68: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "WARNING:tensorflow:From /caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/keras_retinanet/backend/tensorflow_backend.py:104: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "tracking <tf.Variable 'Variable:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_1:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_2:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_3:0' shape=(9, 4) dtype=float32> anchors\n",
      "tracking <tf.Variable 'Variable_4:0' shape=(9, 4) dtype=float32> anchors\n"
     ]
    }
   ],
   "source": [
    "# show images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# automatically reload modules when they have changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = str(1)\n",
    "\n",
    "# import keras\n",
    "import keras\n",
    "\n",
    "# import keras_retinanet\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet.utils.image import read_image_bgr, preprocess_image, resize_image\n",
    "from keras_retinanet.utils.visualization import draw_box, draw_caption\n",
    "from keras_retinanet.utils.colors import label_color\n",
    "#from keras_retinanet.utils.gpu import setup_gpu\n",
    "\n",
    "# import miscellaneous modules\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# set tf backend to allow memory to grow, instead of claiming everything\n",
    "import tensorflow as tf\n",
    "\n",
    "# use this to change which GPU to use\n",
    "#gpu = 1\n",
    "\n",
    "# set the modified tf session as backend in keras\n",
    "#setup_gpu(gpu)\n",
    "\n",
    "from keras_retinanet import models\n",
    "\n",
    "# adjust this to point to your downloaded/trained model\n",
    "# models can be downloaded here: https://github.com/fizyr/keras-retinanet/releases\n",
    "model_path = os.path.join('..', 'snapshots', 'resnet152_pascal_02_backup.h5')\n",
    "dataset_path = \"/caa/Homes01/mburges/CVSP-Object-Detection-Historical-Videos/retina_net_video/output/\"\n",
    "\n",
    "# load retinanet model\n",
    "model = models.load_model(model_path, backbone_name='resnet152')\n",
    "\n",
    "model = models.convert_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load RetinaNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load label to names mapping for visualization purposes\n",
    "labels_to_names = {0: 'crowd', 1: 'civilian', 2: 'soldier', 3: 'civil vehicle', 4: 'mv'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run detection on example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  14.983539581298828\n",
      "processing time:  0.12204432487487793\n",
      "processing time:  0.09300637245178223\n",
      "[607.5637  225.40349 737.20013 603.96277] 1 0.88375086\n",
      "processing time:  0.09206128120422363\n",
      "[486.1151  155.2592  717.5609  624.07947] 1 0.52050894\n",
      "processing time:  0.09435248374938965\n",
      "processing time:  0.09000372886657715\n",
      "processing time:  0.0921483039855957\n",
      "processing time:  0.09550046920776367\n",
      "[510.8549  137.49898 804.9428  553.4199 ] 2 0.8575064\n",
      "processing time:  0.09555768966674805\n",
      "processing time:  0.09353828430175781\n",
      "processing time:  0.09651637077331543\n",
      "processing time:  0.09403705596923828\n",
      "[347.28036  79.86496 527.74695 608.31683] 2 0.5910789\n",
      "[347.28036  79.86496 527.74695 608.31683] 1 0.517396\n",
      "processing time:  0.09273624420166016\n",
      "[425.68863 119.19557 676.1325  627.0878 ] 1 0.5313673\n",
      "processing time:  0.0914297103881836\n",
      "[371.56665 168.74414 513.4851  540.01263] 2 0.70219386\n",
      "[371.80887 168.88281 513.1104  547.34534] 1 0.53447974\n",
      "processing time:  0.09416532516479492\n",
      "processing time:  0.09432744979858398\n",
      "processing time:  0.09474587440490723\n",
      "processing time:  0.09543561935424805\n",
      "processing time:  0.09648942947387695\n",
      "processing time:  0.09536194801330566\n",
      "processing time:  0.09453773498535156\n",
      "[414.67847 263.89792 499.37177 378.30865] 1 0.9172611\n",
      "processing time:  0.09071469306945801\n",
      "processing time:  0.08962607383728027\n",
      "[451.50555 195.46921 696.44965 679.3483 ] 1 0.5325235\n",
      "processing time:  0.09146785736083984\n",
      "[376.33533 167.56775 492.77762 396.34012] 1 0.7805066\n",
      "processing time:  0.09313607215881348\n",
      "[456.04694 156.29828 673.3232  628.95074] 1 0.7096983\n",
      "processing time:  0.09243106842041016\n",
      "processing time:  0.09106063842773438\n",
      "processing time:  0.09378266334533691\n",
      "processing time:  0.10053062438964844\n",
      "[436.5713   63.5298  831.2737  684.41486] 2 0.6563158\n",
      "processing time:  0.1033942699432373\n",
      "processing time:  0.09522390365600586\n",
      "processing time:  0.09610199928283691\n",
      "[239.43962 188.80275 419.7838  668.23425] 1 0.8739916\n",
      "processing time:  0.0928342342376709\n",
      "processing time:  0.09429478645324707\n",
      "processing time:  0.0940711498260498\n",
      "[500.65585 205.6814  736.7623  589.0865 ] 2 0.9546621\n",
      "processing time:  0.09396195411682129\n",
      "processing time:  0.09192037582397461\n",
      "processing time:  0.0907444953918457\n",
      "processing time:  0.09572935104370117\n",
      "processing time:  0.09575319290161133\n",
      "processing time:  0.08878946304321289\n",
      "processing time:  0.0968015193939209\n",
      "processing time:  0.08921289443969727\n",
      "processing time:  0.09622716903686523\n",
      "processing time:  0.09737372398376465\n",
      "processing time:  0.09994244575500488\n",
      "[576.2696  298.4631  792.2819  609.51874] 1 0.8295926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing time:  0.09222602844238281\n",
      "Traceback (most recent call last):\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3319, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-3-5e40e6dd715f>\", line 14, in <module>\n",
      "    image = preprocess_image(image)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/keras_retinanet/utils/image.py\", line 59, in preprocess_image\n",
      "    x[..., 1] -= 116.779\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2034, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/posixpath.py\", line 428, in _joinrealpath\n",
      "    newpath = join(path, name)\n",
      "  File \"/caa/Homes01/mburges/anaconda3/envs/testRetinaNet/lib/python3.7/posixpath.py\", line 75, in join\n",
      "    def join(a, *p):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(dataset_path):\n",
    "    image = None\n",
    "    if filename.endswith('.jpg'):\n",
    "\n",
    "        # Open the file:\n",
    "        image = cv2.imread(os.path.join(dataset_path,filename))\n",
    "    if image is not None:\n",
    "        # copy to draw on\n",
    "        draw = image.copy()\n",
    "        draw_regression = image.copy()\n",
    "        draw = cv2.cvtColor(draw, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # preprocess image for network\n",
    "        image = preprocess_image(image)\n",
    "        image, scale = resize_image(image)\n",
    "\n",
    "        # process image\n",
    "        start = time.time()\n",
    "        result = model.predict_on_batch(np.expand_dims(image, axis=0))\n",
    "        boxes, scores, labels = result\n",
    "        print(\"processing time: \", time.time() - start)\n",
    "\n",
    "        # correct for image scale\n",
    "        boxes /= scale\n",
    "\n",
    "        # visualize detections\n",
    "        for box, score, label in zip(boxes[0], scores[0], labels[0]):\n",
    "            # scores are sorted so we can break\n",
    "            if score < 0.5:\n",
    "                break\n",
    "\n",
    "            print (box, label, score)\n",
    "            color = label_color(label)\n",
    "\n",
    "            b = box.astype(int)\n",
    "            draw_box(draw, b, color=color)\n",
    "\n",
    "            caption = \"{} {:.3f}\".format(labels_to_names[label], score)\n",
    "            draw_caption(draw, b, caption)\n",
    "\n",
    "        cv2.imwrite(os.path.join(dataset_path,\"detected_\"+filename), draw)\n",
    "#plt.figure(figsize=(17, 17))\n",
    "#plt.axis('off')\n",
    "#plt.imshow(draw)\n",
    "#plt.savefig('/caa/Homes01/mburges/CVSP-Object-Detection-Historical-Videos/result.png')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RetinaNetTest",
   "language": "python",
   "name": "testretinanet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
